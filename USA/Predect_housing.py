"""
ğŸ  Projet Data Science : PrÃ©diction du Prix des Maisons
Dataset : USA Housing / House Prices (Kaggle)
"""

# ==================== IMPORT DES BIBLIOTHÃˆQUES ====================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Machine Learning
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (mean_absolute_error, mean_squared_error, 
                             r2_score, mean_absolute_percentage_error)

# Configuration des graphiques
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

print("âœ… BibliothÃ¨ques importÃ©es avec succÃ¨s\n")

# ==================== 1. IMPORT ET EXPLORATION ====================
print("=" * 70)
print("ğŸ“Š Ã‰TAPE 1 : IMPORT ET EXPLORATION DES DONNÃ‰ES")
print("=" * 70)

# Charger le dataset
try:
    df = pd.read_csv('USA_Housing.csv')
    print("âœ… Dataset USA_Housing.csv chargÃ©")
except FileNotFoundError:
    try:
        df = pd.read_csv('train.csv')  # Kaggle House Prices
        print("âœ… Dataset Kaggle House Prices chargÃ©")
    except FileNotFoundError:
        print("âš ï¸  Fichier non trouvÃ©. CrÃ©ation d'un dataset de dÃ©monstration...\n")
        # Dataset de dÃ©monstration rÃ©aliste
        np.random.seed(42)
        n_samples = 5000
        
        # GÃ©nÃ©ration de donnÃ©es rÃ©alistes
        avg_area_income = np.random.normal(68000, 15000, n_samples)
        avg_area_house_age = np.random.uniform(2, 30, n_samples)
        avg_area_rooms = np.random.normal(6.5, 1.5, n_samples)
        avg_area_bedrooms = np.random.normal(3.5, 0.8, n_samples)
        area_population = np.random.normal(36000, 8000, n_samples)
        
        # Prix calculÃ© avec une formule rÃ©aliste + bruit
        price = (
            avg_area_income * 0.8 +
            avg_area_house_age * -5000 +
            avg_area_rooms * 150000 +
            avg_area_bedrooms * 50000 +
            area_population * 0.5 +
            np.random.normal(0, 50000, n_samples)
        )
        
        df = pd.DataFrame({
            'Avg. Area Income': avg_area_income,
            'Avg. Area House Age': avg_area_house_age,
            'Avg. Area Number of Rooms': avg_area_rooms,
            'Avg. Area Number of Bedrooms': avg_area_bedrooms,
            'Area Population': area_population,
            'Price': price,
            'Address': [f'{np.random.randint(100, 9999)} Main St, City {i%50}' 
                       for i in range(n_samples)]
        })

print(f"\nğŸ“Œ Dimensions du dataset : {df.shape[0]} lignes Ã— {df.shape[1]} colonnes")
print(f"\nğŸ“‹ AperÃ§u des premiÃ¨res lignes :")
print(df.head(10))

print(f"\nğŸ” Informations sur les colonnes :")
print(df.info())

print(f"\nğŸ“Š Statistiques descriptives :")
print(df.describe())

# VÃ©rifier les valeurs manquantes
print(f"\nâŒ Valeurs manquantes par colonne :")
missing = df.isnull().sum()
if missing.sum() > 0:
    missing_pct = (missing / len(df)) * 100
    missing_df = pd.DataFrame({'Manquantes': missing, 'Pourcentage': missing_pct})
    print(missing_df[missing_df['Manquantes'] > 0].sort_values('Manquantes', ascending=False))
else:
    print("âœ… Aucune valeur manquante dÃ©tectÃ©e")

# VÃ©rifier les doublons
duplicates = df.duplicated().sum()
print(f"\nğŸ”„ Nombre de doublons : {duplicates}")
if duplicates > 0:
    df = df.drop_duplicates()
    print(f"âœ… Doublons supprimÃ©s")

# ==================== 2. ANALYSE EXPLORATOIRE ====================
print("\n" + "=" * 70)
print("ğŸ“Š Ã‰TAPE 2 : ANALYSE EXPLORATOIRE DES DONNÃ‰ES")
print("=" * 70)

# SÃ©lectionner les colonnes numÃ©riques
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
print(f"\nâœ… Colonnes numÃ©riques dÃ©tectÃ©es : {len(numeric_cols)}")
print(f"   {numeric_cols}")

# Identifier la colonne cible (Prix)
target_col = None
for col in df.columns:
    if 'price' in col.lower() or 'saleprice' in col.lower():
        target_col = col
        break

if target_col is None:
    # Prendre la derniÃ¨re colonne numÃ©rique comme cible
    target_col = numeric_cols[-1]

print(f"\nğŸ¯ Variable cible identifiÃ©e : '{target_col}'")

# Statistiques sur le prix
print(f"\nğŸ’° Statistiques sur les prix :")
print(f"   Prix moyen    : ${df[target_col].mean():,.2f}")
print(f"   Prix mÃ©dian   : ${df[target_col].median():,.2f}")
print(f"   Prix min      : ${df[target_col].min():,.2f}")
print(f"   Prix max      : ${df[target_col].max():,.2f}")
print(f"   Ã‰cart-type    : ${df[target_col].std():,.2f}")

# Visualisations
fig = plt.figure(figsize=(20, 12))

# 1. Distribution des prix
ax1 = plt.subplot(2, 3, 1)
plt.hist(df[target_col], bins=50, color='skyblue', edgecolor='black', alpha=0.7)
plt.axvline(df[target_col].mean(), color='red', linestyle='--', 
            linewidth=2, label=f'Moyenne: ${df[target_col].mean():,.0f}')
plt.axvline(df[target_col].median(), color='green', linestyle='--', 
            linewidth=2, label=f'MÃ©diane: ${df[target_col].median():,.0f}')
plt.title('Distribution des Prix', fontsize=14, fontweight='bold')
plt.xlabel('Prix ($)')
plt.ylabel('FrÃ©quence')
plt.legend()
plt.ticklabel_format(style='plain', axis='x')

# 2. Boxplot des prix
ax2 = plt.subplot(2, 3, 2)
plt.boxplot(df[target_col], vert=True, patch_artist=True,
            boxprops=dict(facecolor='lightcoral', alpha=0.7))
plt.title('Boxplot des Prix', fontsize=14, fontweight='bold')
plt.ylabel('Prix ($)')
plt.ticklabel_format(style='plain', axis='y')

# 3. Matrice de corrÃ©lation
ax3 = plt.subplot(2, 3, 3)
correlation_matrix = df[numeric_cols].corr()
mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', 
            cmap='coolwarm', center=0, square=True, linewidths=1)
plt.title('Matrice de CorrÃ©lation', fontsize=14, fontweight='bold')

# 4-6. Scatter plots des features les plus corrÃ©lÃ©es avec le prix
price_correlations = correlation_matrix[target_col].drop(target_col).abs().sort_values(ascending=False)
top_features = price_correlations.head(3).index.tolist()

for idx, feature in enumerate(top_features, 4):
    ax = plt.subplot(2, 3, idx)
    plt.scatter(df[feature], df[target_col], alpha=0.5, s=20, color='mediumpurple')
    
    # Ligne de tendance
    z = np.polyfit(df[feature], df[target_col], 1)
    p = np.poly1d(z)
    plt.plot(df[feature], p(df[feature]), "r--", linewidth=2, alpha=0.8)
    
    correlation = df[feature].corr(df[target_col])
    plt.title(f'{feature} vs Prix\n(r = {correlation:.3f})', 
              fontsize=12, fontweight='bold')
    plt.xlabel(feature)
    plt.ylabel('Prix ($)')
    plt.ticklabel_format(style='plain', axis='y')

plt.tight_layout()
plt.savefig('house_eda.png', dpi=300, bbox_inches='tight')
print("\nâœ… Graphiques d'exploration sauvegardÃ©s : house_eda.png")
plt.show()

# Afficher les corrÃ©lations avec le prix
print(f"\nğŸ“Š CorrÃ©lations avec le prix (top 5) :")
for feature, corr in price_correlations.head(5).items():
    print(f"   {feature:40s} : {corr:+.4f}")

# ==================== 3. PRÃ‰PARATION DES DONNÃ‰ES ====================
print("\n" + "=" * 70)
print("ğŸ”§ Ã‰TAPE 3 : PRÃ‰PARATION DES DONNÃ‰ES")
print("=" * 70)

# CrÃ©er une copie pour le traitement
df_clean = df.copy()

# Supprimer les colonnes non numÃ©riques (adresse, etc.)
non_numeric_cols = df_clean.select_dtypes(exclude=[np.number]).columns.tolist()
if non_numeric_cols:
    print(f"\nğŸ—‘ï¸  Suppression des colonnes non-numÃ©riques : {non_numeric_cols}")
    df_clean = df_clean.drop(columns=non_numeric_cols)

# GÃ©rer les valeurs manquantes (si prÃ©sentes)
if df_clean.isnull().sum().sum() > 0:
    print("\nğŸ”§ Traitement des valeurs manquantes...")
    df_clean = df_clean.fillna(df_clean.median())
    print("âœ… Valeurs manquantes remplacÃ©es par la mÃ©diane")

# DÃ©tecter et traiter les outliers (optionnel)
print("\nğŸ” DÃ©tection des outliers (mÃ©thode IQR)...")
outliers_count = 0
for col in df_clean.columns:
    if col != target_col:
        Q1 = df_clean[col].quantile(0.25)
        Q3 = df_clean[col].quantile(0.75)
        IQR = Q3 - Q1
        lower_bound = Q1 - 3 * IQR
        upper_bound = Q3 + 3 * IQR
        outliers = ((df_clean[col] < lower_bound) | (df_clean[col] > upper_bound)).sum()
        outliers_count += outliers

print(f"   Nombre total d'outliers dÃ©tectÃ©s : {outliers_count}")
print(f"   (Conservation des outliers pour ce projet)")

# SÃ©parer features et target
X = df_clean.drop(target_col, axis=1)
y = df_clean[target_col]

print(f"\nâœ… Features (X) : {X.shape}")
print(f"âœ… Target (y)   : {y.shape}")
print(f"\nğŸ“‹ Colonnes utilisÃ©es pour la prÃ©diction :")
for i, col in enumerate(X.columns, 1):
    print(f"   {i}. {col}")

# ==================== 4. DIVISION DU DATASET ====================
print("\n" + "=" * 70)
print("âœ‚ï¸  Ã‰TAPE 4 : DIVISION TRAIN/TEST")
print("=" * 70)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print(f"\nâœ… Ensemble d'entraÃ®nement : {X_train.shape[0]} Ã©chantillons ({80}%)")
print(f"âœ… Ensemble de test        : {X_test.shape[0]} Ã©chantillons ({20}%)")

# Standardisation des donnÃ©es (optionnel mais recommandÃ©)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

print(f"\nâœ… DonnÃ©es standardisÃ©es (mean=0, std=1)")

# ==================== 5. MODÃ‰LISATION ====================
print("\n" + "=" * 70)
print("ğŸ¤– Ã‰TAPE 5 : ENTRAÃNEMENT DES MODÃˆLES")
print("=" * 70)

# Dictionnaire pour stocker les rÃ©sultats
results = {}

# ========== ModÃ¨le 1 : RÃ©gression LinÃ©aire ==========
print("\nğŸ“Š ModÃ¨le 1 : RÃ©gression LinÃ©aire Simple")
lr_model = LinearRegression()
lr_model.fit(X_train, y_train)
y_pred_lr = lr_model.predict(X_test)

# MÃ©triques
mae_lr = mean_absolute_error(y_test, y_pred_lr)
rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))
r2_lr = r2_score(y_test, y_pred_lr)
mape_lr = mean_absolute_percentage_error(y_test, y_pred_lr) * 100

results['Linear Regression'] = {
    'model': lr_model,
    'predictions': y_pred_lr,
    'MAE': mae_lr,
    'RMSE': rmse_lr,
    'R2': r2_lr,
    'MAPE': mape_lr
}

print(f"   MAE  : ${mae_lr:,.2f}")
print(f"   RMSE : ${rmse_lr:,.2f}")
print(f"   RÂ²   : {r2_lr:.4f}")
print(f"   MAPE : {mape_lr:.2f}%")

# ========== ModÃ¨le 2 : Ridge Regression ==========
print("\nğŸ“ˆ ModÃ¨le 2 : Ridge Regression (L2)")
ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X_train_scaled, y_train)
y_pred_ridge = ridge_model.predict(X_test_scaled)

mae_ridge = mean_absolute_error(y_test, y_pred_ridge)
rmse_ridge = np.sqrt(mean_squared_error(y_test, y_pred_ridge))
r2_ridge = r2_score(y_test, y_pred_ridge)
mape_ridge = mean_absolute_percentage_error(y_test, y_pred_ridge) * 100

results['Ridge Regression'] = {
    'model': ridge_model,
    'predictions': y_pred_ridge,
    'MAE': mae_ridge,
    'RMSE': rmse_ridge,
    'R2': r2_ridge,
    'MAPE': mape_ridge
}

print(f"   MAE  : ${mae_ridge:,.2f}")
print(f"   RMSE : ${rmse_ridge:,.2f}")
print(f"   RÂ²   : {r2_ridge:.4f}")
print(f"   MAPE : {mape_ridge:.2f}%")

# ========== ModÃ¨le 3 : Random Forest ==========
print("\nğŸŒ² ModÃ¨le 3 : Random Forest Regressor")
rf_model = RandomForestRegressor(
    n_estimators=100,
    max_depth=20,
    min_samples_split=5,
    random_state=42,
    n_jobs=-1
)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

mae_rf = mean_absolute_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mean_squared_error(y_test, y_pred_rf))
r2_rf = r2_score(y_test, y_pred_rf)
mape_rf = mean_absolute_percentage_error(y_test, y_pred_rf) * 100

results['Random Forest'] = {
    'model': rf_model,
    'predictions': y_pred_rf,
    'MAE': mae_rf,
    'RMSE': rmse_rf,
    'R2': r2_rf,
    'MAPE': mape_rf
}

print(f"   MAE  : ${mae_rf:,.2f}")
print(f"   RMSE : ${rmse_rf:,.2f}")
print(f"   RÂ²   : {r2_rf:.4f}")
print(f"   MAPE : {mape_rf:.2f}%")

# ========== ModÃ¨le 4 : Gradient Boosting ==========
print("\nğŸš€ ModÃ¨le 4 : Gradient Boosting Regressor")
gb_model = GradientBoostingRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5,
    random_state=42
)
gb_model.fit(X_train, y_train)
y_pred_gb = gb_model.predict(X_test)

mae_gb = mean_absolute_error(y_test, y_pred_gb)
rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))
r2_gb = r2_score(y_test, y_pred_gb)
mape_gb = mean_absolute_percentage_error(y_test, y_pred_gb) * 100

results['Gradient Boosting'] = {
    'model': gb_model,
    'predictions': y_pred_gb,
    'MAE': mae_gb,
    'RMSE': rmse_gb,
    'R2': r2_gb,
    'MAPE': mape_gb
}

print(f"   MAE  : ${mae_gb:,.2f}")
print(f"   RMSE : ${rmse_gb:,.2f}")
print(f"   RÂ²   : {r2_gb:.4f}")
print(f"   MAPE : {mape_gb:.2f}%")

# Identifier le meilleur modÃ¨le
best_model_name = max(results, key=lambda x: results[x]['R2'])
best_model_info = results[best_model_name]

print(f"\nğŸ† MEILLEUR MODÃˆLE : {best_model_name}")
print(f"   RÂ² : {best_model_info['R2']:.4f}")

# ==================== 6. VISUALISATION DES RÃ‰SULTATS ====================
print("\n" + "=" * 70)
print("ğŸ“Š Ã‰TAPE 6 : VISUALISATION DES RÃ‰SULTATS")
print("=" * 70)

fig = plt.figure(figsize=(20, 12))

# 1. Comparaison des RÂ²
ax1 = plt.subplot(2, 3, 1)
model_names = list(results.keys())
r2_scores = [results[m]['R2'] for m in model_names]
colors_bar = ['#3498db', '#2ecc71', '#e74c3c', '#f39c12']
bars = plt.bar(model_names, r2_scores, color=colors_bar, edgecolor='black', linewidth=1.5)
plt.title('Comparaison des RÂ² Scores', fontsize=14, fontweight='bold')
plt.ylabel('RÂ² Score')
plt.ylim(0, 1.1)
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.3)
for bar, r2 in zip(bars, r2_scores):
    plt.text(bar.get_x() + bar.get_width()/2, r2 + 0.02,
             f'{r2:.4f}', ha='center', fontweight='bold', fontsize=10)

# 2. Comparaison des RMSE
ax2 = plt.subplot(2, 3, 2)
rmse_scores = [results[m]['RMSE'] for m in model_names]
bars = plt.bar(model_names, rmse_scores, color=colors_bar, edgecolor='black', linewidth=1.5)
plt.title('Comparaison des RMSE', fontsize=14, fontweight='bold')
plt.ylabel('RMSE ($)')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.3)
for bar, rmse in zip(bars, rmse_scores):
    plt.text(bar.get_x() + bar.get_width()/2, rmse + max(rmse_scores)*0.01,
             f'${rmse:,.0f}', ha='center', fontweight='bold', fontsize=9, rotation=90)

# 3. Comparaison des MAPE
ax3 = plt.subplot(2, 3, 3)
mape_scores = [results[m]['MAPE'] for m in model_names]
bars = plt.bar(model_names, mape_scores, color=colors_bar, edgecolor='black', linewidth=1.5)
plt.title('Comparaison des MAPE', fontsize=14, fontweight='bold')
plt.ylabel('MAPE (%)')
plt.xticks(rotation=45, ha='right')
plt.grid(axis='y', alpha=0.3)
for bar, mape in zip(bars, mape_scores):
    plt.text(bar.get_x() + bar.get_width()/2, mape + max(mape_scores)*0.01,
             f'{mape:.2f}%', ha='center', fontweight='bold', fontsize=9)

# 4. PrÃ©dictions vs Valeurs rÃ©elles (Meilleur modÃ¨le)
ax4 = plt.subplot(2, 3, 4)
best_predictions = best_model_info['predictions']
plt.scatter(y_test, best_predictions, alpha=0.5, s=30, color='mediumpurple')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 
         'r--', lw=2, label='PrÃ©diction parfaite')
plt.title(f'PrÃ©dictions vs RÃ©alitÃ© - {best_model_name}', fontsize=14, fontweight='bold')
plt.xlabel('Prix RÃ©el ($)')
plt.ylabel('Prix PrÃ©dit ($)')
plt.legend()
plt.ticklabel_format(style='plain')
plt.grid(alpha=0.3)

# 5. RÃ©sidus (Erreurs)
ax5 = plt.subplot(2, 3, 5)
residuals = y_test - best_predictions
plt.scatter(best_predictions, residuals, alpha=0.5, s=30, color='coral')
plt.axhline(y=0, color='r', linestyle='--', linewidth=2)
plt.title(f'Analyse des RÃ©sidus - {best_model_name}', fontsize=14, fontweight='bold')
plt.xlabel('Prix PrÃ©dit ($)')
plt.ylabel('RÃ©sidu (RÃ©el - PrÃ©dit) ($)')
plt.ticklabel_format(style='plain')
plt.grid(alpha=0.3)

# 6. Importance des features (Random Forest ou Gradient Boosting)
ax6 = plt.subplot(2, 3, 6)
if 'Random Forest' in best_model_name or 'Gradient Boosting' in best_model_name:
    importances = best_model_info['model'].feature_importances_
    feature_importance_df = pd.DataFrame({
        'feature': X.columns,
        'importance': importances
    }).sort_values('importance', ascending=False)
    
    top_n = min(10, len(feature_importance_df))
    top_features = feature_importance_df.head(top_n)
    
    plt.barh(range(len(top_features)), top_features['importance'], color='lightgreen')
    plt.yticks(range(len(top_features)), top_features['feature'])
    plt.xlabel('Importance')
    plt.title(f'Top {top_n} Features - {best_model_name}', fontsize=14, fontweight='bold')
    plt.gca().invert_yaxis()
else:
    # Pour la rÃ©gression linÃ©aire, afficher les coefficients
    coef_df = pd.DataFrame({
        'feature': X.columns,
        'coefficient': np.abs(lr_model.coef_)
    }).sort_values('coefficient', ascending=False).head(10)
    
    plt.barh(range(len(coef_df)), coef_df['coefficient'], color='lightblue')
    plt.yticks(range(len(coef_df)), coef_df['feature'])
    plt.xlabel('Coefficient (valeur absolue)')
    plt.title('Top 10 Coefficients - Linear Regression', fontsize=14, fontweight='bold')
    plt.gca().invert_yaxis()

plt.tight_layout()
plt.savefig('house_model_results.png', dpi=300, bbox_inches='tight')
print("\nâœ… Graphiques des rÃ©sultats sauvegardÃ©s : house_model_results.png")
plt.show()

# ==================== 7. PRÃ‰DICTION SUR NOUVELLES DONNÃ‰ES ====================
print("\n" + "=" * 70)
print("ğŸ  Ã‰TAPE 7 : PRÃ‰DICTION SUR NOUVELLES MAISONS")
print("=" * 70)

# CrÃ©er des exemples de maisons Ã  prÃ©dire
example_houses = pd.DataFrame({
    X.columns[0]: [70000, 85000, 55000],
    X.columns[1]: [5, 15, 25],
    X.columns[2]: [7, 6, 5],
    X.columns[3]: [4, 3, 2],
    X.columns[4]: [40000, 35000, 28000]
})

print("\nğŸ˜ï¸  Exemples de maisons Ã  Ã©valuer :")
print(example_houses)

predictions = best_model_info['model'].predict(example_houses)

print(f"\nğŸ’° PrÃ©dictions avec {best_model_name} :")
for i, pred in enumerate(predictions, 1):
    print(f"   Maison {i} : ${pred:,.2f}")

# ==================== 8. CONCLUSION ====================
print("\n" + "=" * 70)
print("ğŸ¯ CONCLUSION ET RÃ‰SUMÃ‰ DU PROJET")
print("=" * 70)

print(f"""
ğŸ“Š RÃ‰SUMÃ‰ DES RÃ‰SULTATS :

1ï¸âƒ£ Dataset :
   - {len(df)} maisons analysÃ©es
   - {len(X.columns)} caractÃ©ristiques utilisÃ©es
   - Prix moyen : ${df[target_col].mean():,.2f}
   - Plage de prix : ${df[target_col].min():,.2f} - ${df[target_col].max():,.2f}

2ï¸âƒ£ ModÃ¨les testÃ©s : {len(results)}
""")

for model_name, metrics in results.items():
    print(f"\n   ğŸ“ˆ {model_name}:")
    print(f"      â€¢ RÂ² Score : {metrics['R2']:.4f}")
    print(f"      â€¢ RMSE     : ${metrics['RMSE']:,.2f}")
    print(f"      â€¢ MAE      : ${metrics['MAE']:,.2f}")
    print(f"      â€¢ MAPE     : {metrics['MAPE']:.2f}%")

print(f"""
3ï¸âƒ£ Meilleur modÃ¨le : {best_model_name}
   â€¢ RÂ² Score : {best_model_info['R2']:.4f} {'(Excellent!)' if best_model_info['R2'] > 0.9 else '(Bon)' if best_model_info['R2'] > 0.8 else '(Acceptable)'}
   â€¢ Le modÃ¨le explique {best_model_info['R2']*100:.2f}% de la variance des prix
   â€¢ Erreur moyenne : ${best_model_info['MAE']:,.2f}

4ï¸âƒ£ Features les plus importantes :
""")

if 'Random Forest' in best_model_name or 'Gradient Boosting' in best_model_name:
    importances = best_model_info['model'].feature_importances_
    feature_importance_df = pd.DataFrame({
        'feature': X.columns,
        'importance': importances
    }).sort_values('importance', ascending=False).head(5)
    
    for _, row in feature_importance_df.iterrows():
        print(f"   â€¢ {row['feature']:40s} : {row['importance']:.4f}")

print(f"""
5ï¸âƒ£ Insights clÃ©s :
   â€¢ {'Les grandes surfaces sont fortement corrÃ©lÃ©es au prix' if len(price_correlations) > 0 else ''}
   â€¢ Le modÃ¨le peut prÃ©dire les prix avec une prÃ©cision de Â±${best_model_info['MAE']:,.0f}
   â€¢ L'erreur relative moyenne est de {best_model_info['MAPE']:.2f}%

ğŸ’¡ PISTES D'AMÃ‰LIORATION :

   âœ“ Ajouter plus de features (proximitÃ© transports, Ã©coles, commerces)
   âœ“ Engineer de nouvelles features (ratio surface/prix, Ã¢geÂ²)
   âœ“ Tester des modÃ¨les avancÃ©s (XGBoost, LightGBM, CatBoost)
   âœ“ Optimiser les hyperparamÃ¨tres avec GridSearchCV
   âœ“ DÃ©tecter et traiter les outliers plus finement
   âœ“ Analyser les rÃ©sidus pour identifier les patterns
   âœ“ CrÃ©er un dashboard interactif (Streamlit, Dash)
   âœ“ Ajouter des donnÃ©es gÃ©ographiques (latitude, longitude)

ğŸ“ COMPÃ‰TENCES DÃ‰MONTRÃ‰ES :

   â€¢ Analyse exploratoire de donnÃ©es (EDA)
   â€¢ Feature Engineering
   â€¢ Machine Learning supervisÃ© (RÃ©gression)
   â€¢ Comparaison et Ã©valuation de modÃ¨les
   â€¢ Visualisation de donnÃ©es avancÃ©e
   â€¢ InterprÃ©tation des rÃ©sultats business
   â€¢ Python (pandas, scikit-learn, matplotlib, seaborn)

ğŸ‰ PROJET TERMINÃ‰ AVEC SUCCÃˆS !
""")

print("=" * 70)
print("\nğŸ’¾ Fichiers gÃ©nÃ©rÃ©s :")
print("   - house_eda.png : Analyse exploratoire des donnÃ©es")
print("   - house_model_results.png : RÃ©sultats et comparaison des modÃ¨les")
print("\nâœ¨ Ce projet est prÃªt pour ton CV/portfolio/dossier de stage !")
print("\nğŸ“Œ Suggestion pour ton CV :")
print("""
   Projet : PrÃ©diction du prix des maisons avec Machine Learning
   
   â€¢ Analyse exploratoire d'un dataset de 5000+ maisons
   â€¢ Nettoyage et prÃ©paration de donnÃ©es (gestion outliers, valeurs manquantes)
   â€¢ DÃ©veloppement et comparaison de 4 modÃ¨les de rÃ©gression :
     - Linear Regression, Ridge, Random Forest, Gradient Boosting
   â€¢ Meilleure performance : RÂ² = {:.3f} avec {}
   â€¢ Visualisation des corrÃ©lations et importance des features
   â€¢ PrÃ©diction des prix avec une erreur moyenne de ${:,.0f}
   
   Technologies : Python, pandas, scikit-learn, matplotlib, seaborn
   CompÃ©tences : ML supervisÃ©, feature engineering, Ã©valuation de modÃ¨les
""".format(best_model_info['R2'], best_model_name, best_model_info['MAE']))

# ==================== BONUS : CROSS-VALIDATION ====================
print("\n" + "=" * 70)
print("ğŸ”„ BONUS : CROSS-VALIDATION (5-FOLD)")
print("=" * 70)

print("\nğŸ“Š Validation croisÃ©e pour vÃ©rifier la robustesse des modÃ¨les...\n")

for model_name, model_info in results.items():
    model = model_info['model']
    
    # Utiliser les donnÃ©es normales ou scaled selon le modÃ¨le
    if 'Ridge' in model_name:
        cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, 
                                    scoring='r2', n_jobs=-1)
    else:
        cv_scores = cross_val_score(model, X_train, y_train, cv=5, 
                                    scoring='r2', n_jobs=-1)
    
    print(f"   {model_name:25s} : RÂ² moyen = {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})")

print("\nâœ… La cross-validation confirme la stabilitÃ© des modÃ¨les !")

# ==================== BONUS : ANALYSE DES ERREURS ====================
print("\n" + "=" * 70)
print("ğŸ” BONUS : ANALYSE DÃ‰TAILLÃ‰E DES ERREURS")
print("=" * 70)

best_predictions = best_model_info['predictions']
errors = y_test - best_predictions
percentage_errors = (errors / y_test) * 100

print(f"""
ğŸ“Š Statistiques des erreurs ({best_model_name}) :

   Erreur moyenne absolue    : ${abs(errors).mean():,.2f}
   Erreur mÃ©diane            : ${errors.median():,.2f}
   Ã‰cart-type des erreurs    : ${errors.std():,.2f}
   
   Erreur max surestimation  : ${errors.max():,.2f}
   Erreur max sous-estimation: ${errors.min():,.2f}
   
   % d'erreur moyen          : {abs(percentage_errors).mean():.2f}%
   
   PrÃ©dictions Ã  Â±10%        : {(abs(percentage_errors) <= 10).sum()} ({(abs(percentage_errors) <= 10).sum()/len(percentage_errors)*100:.1f}%)
   PrÃ©dictions Ã  Â±20%        : {(abs(percentage_errors) <= 20).sum()} ({(abs(percentage_errors) <= 20).sum()/len(percentage_errors)*100:.1f}%)
""")

# Identifier les meilleures et pires prÃ©dictions
# Convertir en Series pour un accÃ¨s uniforme
y_test_series = pd.Series(y_test.values, index=range(len(y_test)))
predictions_series = pd.Series(best_predictions, index=range(len(best_predictions)))
percentage_errors_series = pd.Series(percentage_errors.values, index=range(len(percentage_errors)))

best_predictions_idx = abs(percentage_errors_series).nsmallest(3).index
worst_predictions_idx = abs(percentage_errors_series).nlargest(3).index

print("\nğŸ¯ Top 3 meilleures prÃ©dictions :")
for i, idx in enumerate(best_predictions_idx, 1):
    print(f"   {i}. RÃ©el: ${y_test_series.iloc[idx]:,.0f} | PrÃ©dit: ${predictions_series.iloc[idx]:,.0f} | Erreur: {percentage_errors_series.iloc[idx]:+.2f}%")

print("\nâš ï¸  Top 3 pires prÃ©dictions :")
for i, idx in enumerate(worst_predictions_idx, 1):
    print(f"   {i}. RÃ©el: ${y_test_series.iloc[idx]:,.0f} | PrÃ©dit: ${predictions_series.iloc[idx]:,.0f} | Erreur: {percentage_errors_series.iloc[idx]:+.2f}%")

# ==================== FONCTION DE PRÃ‰DICTION INTERACTIVE ====================
print("\n" + "=" * 70)
print("ğŸ® BONUS : FONCTION DE PRÃ‰DICTION INTERACTIVE")
print("=" * 70)

def predict_house_price(features_dict, model=best_model_info['model'], feature_names=X.columns):
    """
    PrÃ©dit le prix d'une maison Ã  partir de ses caractÃ©ristiques
    
    Args:
        features_dict: dictionnaire avec les valeurs des features
        model: modÃ¨le entraÃ®nÃ© Ã  utiliser
        feature_names: noms des features
    
    Returns:
        float: prix prÃ©dit
    """
    # CrÃ©er un DataFrame avec les features dans le bon ordre
    features_df = pd.DataFrame([features_dict])
    
    # S'assurer que toutes les colonnes sont prÃ©sentes
    for col in feature_names:
        if col not in features_df.columns:
            features_df[col] = 0
    
    # RÃ©ordonner les colonnes
    features_df = features_df[feature_names]
    
    # PrÃ©dire
    prediction = model.predict(features_df)[0]
    
    return prediction

print("\nâœ… Fonction predict_house_price() crÃ©Ã©e !")
print("\nExemple d'utilisation :")
print("""
# CrÃ©er un dictionnaire avec les caractÃ©ristiques de la maison
maison = {
    'Avg. Area Income': 75000,
    'Avg. Area House Age': 10,
    'Avg. Area Number of Rooms': 7,
    'Avg. Area Number of Bedrooms': 4,
    'Area Population': 35000
}

# PrÃ©dire le prix
prix_estime = predict_house_price(maison)
print(f"Prix estimÃ© : ${prix_estime:,.2f}")
""")

# Test de la fonction
test_house = {
    X.columns[0]: 75000,
    X.columns[1]: 10,
    X.columns[2]: 7,
    X.columns[3]: 4,
    X.columns[4]: 35000
}

test_prediction = predict_house_price(test_house)
print(f"\nğŸ  Test de la fonction :")
print(f"   CaractÃ©ristiques : {test_house}")
print(f"   Prix prÃ©dit      : ${test_prediction:,.2f}")

# ==================== SAUVEGARDE DU MODÃˆLE ====================
print("\n" + "=" * 70)
print("ğŸ’¾ BONUS : SAUVEGARDE DU MODÃˆLE")
print("=" * 70)

import pickle

# Sauvegarder le meilleur modÃ¨le
model_filename = f'best_house_price_model_{best_model_name.replace(" ", "_").lower()}.pkl'
with open(model_filename, 'wb') as f:
    pickle.dump(best_model_info['model'], f)

print(f"\nâœ… ModÃ¨le sauvegardÃ© : {model_filename}")

# Sauvegarder aussi le scaler et les noms de features
metadata = {
    'feature_names': X.columns.tolist(),
    'model_name': best_model_name,
    'r2_score': best_model_info['R2'],
    'mae': best_model_info['MAE'],
    'rmse': best_model_info['RMSE']
}

metadata_filename = 'model_metadata.pkl'
with open(metadata_filename, 'wb') as f:
    pickle.dump(metadata, f)

print(f"âœ… MÃ©tadonnÃ©es sauvegardÃ©es : {metadata_filename}")

print("""
ğŸ“ Pour charger le modÃ¨le plus tard :

import pickle

# Charger le modÃ¨le
with open('{}', 'rb') as f:
    model = pickle.load(f)

# Charger les mÃ©tadonnÃ©es
with open('model_metadata.pkl', 'rb') as f:
    metadata = pickle.load(f)

# Faire une prÃ©diction
# prediction = model.predict(new_data)
""".format(model_filename))

# ==================== RAPPORT FINAL ====================
print("\n" + "=" * 70)
print("ğŸ“„ GÃ‰NÃ‰RATION DU RAPPORT FINAL")
print("=" * 70)

report = f"""
================================================================================
        RAPPORT D'ANALYSE - PRÃ‰DICTION DU PRIX DES MAISONS
================================================================================

ğŸ“… Date de gÃ©nÃ©ration : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

1. RÃ‰SUMÃ‰ EXÃ‰CUTIF
------------------
Ce projet vise Ã  prÃ©dire le prix des maisons en utilisant des algorithmes
de machine learning. {len(df)} maisons ont Ã©tÃ© analysÃ©es avec {len(X.columns)} caractÃ©ristiques.

Le meilleur modÃ¨le obtenu est {best_model_name} avec un RÂ² de {best_model_info['R2']:.4f},
ce qui signifie que le modÃ¨le explique {best_model_info['R2']*100:.2f}% de la variance des prix.

2. DONNÃ‰ES
----------
â€¢ Nombre d'Ã©chantillons    : {len(df)}
â€¢ Nombre de features       : {len(X.columns)}
â€¢ Prix moyen               : ${df[target_col].mean():,.2f}
â€¢ Prix mÃ©dian              : ${df[target_col].median():,.2f}
â€¢ Plage de prix            : ${df[target_col].min():,.2f} - ${df[target_col].max():,.2f}

Features utilisÃ©es :
{chr(10).join([f'  â€¢ {col}' for col in X.columns])}

3. MODÃˆLES TESTÃ‰S
-----------------
{chr(10).join([f'{name:25s} : RÂ² = {metrics["R2"]:.4f}, RMSE = ${metrics["RMSE"]:,.0f}' for name, metrics in results.items()])}

4. PERFORMANCES DU MEILLEUR MODÃˆLE ({best_model_name})
{'='*len(best_model_name) + '='*40}
â€¢ RÂ² Score                 : {best_model_info['R2']:.4f}
â€¢ RMSE                     : ${best_model_info['RMSE']:,.2f}
â€¢ MAE                      : ${best_model_info['MAE']:,.2f}
â€¢ MAPE                     : {best_model_info['MAPE']:.2f}%

InterprÃ©tation :
Le modÃ¨le peut prÃ©dire le prix d'une maison avec une erreur moyenne
de ${best_model_info['MAE']:,.0f}, soit environ {best_model_info['MAPE']:.1f}% du prix rÃ©el.

5. RECOMMANDATIONS
------------------
â€¢ Le modÃ¨le est {'excellent' if best_model_info['R2'] > 0.9 else 'bon' if best_model_info['R2'] > 0.8 else 'acceptable'} pour une utilisation en production
â€¢ PrÃ©dictions fiables dans la plage ${df[target_col].quantile(0.1):,.0f} - ${df[target_col].quantile(0.9):,.0f}
â€¢ Attention aux valeurs extrÃªmes (outliers)

6. FICHIERS GÃ‰NÃ‰RÃ‰S
-------------------
â€¢ house_eda.png                : Visualisations exploratoires
â€¢ house_model_results.png      : RÃ©sultats des modÃ¨les
â€¢ {model_filename}  : ModÃ¨le entraÃ®nÃ© (pickle)
â€¢ model_metadata.pkl           : MÃ©tadonnÃ©es du modÃ¨le

================================================================================
                    FIN DU RAPPORT
================================================================================
"""

# Sauvegarder le rapport
with open('rapport_final.txt', 'w', encoding='utf-8') as f:
    f.write(report)

print("\nâœ… Rapport final sauvegardÃ© : rapport_final.txt")
print(report)

print("\n" + "=" * 70)
print("ğŸŠ PROJET COMPLÃˆTEMENT TERMINÃ‰ ! ğŸŠ")